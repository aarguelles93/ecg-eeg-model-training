(tf-gpu-env) root@DESKTOP-08HJS8G:/mnt/d/Documents/Projects/Thesis/src# python train.py all --dataset-fraction 0.15 --normalization per_sample
🔧 Environment variables set for TensorFlow/CUDA compatibility
✅ Import safety check passed - TensorFlow not yet imported
2025-06-06 01:23:58.893071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-06-06 01:24:07.057461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
🔧 Setting up GPU configuration...
🚀 Setting up GPU-friendly configuration for GTX 1050 (2GB VRAM)...
✅ CUDA libdevice path set to: /usr/lib/cuda
🔧 Configuring GPU memory settings...
2025-06-06 01:24:26.950701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:24:28.854869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:24:28.855066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
✅ Found 1 GPU(s): ['/physical_device:GPU:0']
✅ Memory growth enabled for /physical_device:GPU:0
🔧 Configuring TensorFlow memory management...
✅ Memory growth enabled for /physical_device:GPU:0
✅ Using float32 precision (optimized for GTX 1050/Pascal)
   This provides better performance than mixed precision on compute capability 6.1
✅ GPU configuration complete! GTX 1050 optimized with correct CUDA paths.
✅ GPU configuration successful - using optimized settings
🚀 ENHANCED TRAINING PIPELINE
======================================================================
🔧 Normalization: per_sample (strategy: separate)
📊 Dataset fraction: 15.0%
💾 Memory limit: 3.5GB
🎯 Validation strategy: auto
📊 Memory monitoring: Enabled
📈 Progress bars: Enabled
🖥️  GPU optimization: Enabled

📊 Initial system status:
💾 Initial memory usage: 0.44GB

📦 Preparing dataset with smart normalization...
🧠 Memory limit applied: 3.5GB
   📊 Calculated chunk size: 5,000 samples
   📊 Estimated memory per chunk: 0.11GB
🔍 Checking cached dataset: data/preprocessed_dataset.npz
✅ Cache parameters match - loading cached data
📊 Cached data loaded:
   Train: (86016, 6016) | Test: (21504, 6016)
   Range: [-4.826004, 5.000000]
✅ Dataset ready!
   📊 Dataset loaded in 54.9s
   🚀 Train: (86016, 6016), Test: (21504, 6016)
   📉 Using 15.0% of full dataset
   📈 Total features: 6,016
   🧠 EEG structure: 32 channels × 188 timepoints
   💾 Memory usage: 5.26GB (Δ+4.82GB)
   🔢 Data range: [-4.826, 5.000]
   📊 Data stats: mean=-0.002794, std=0.984329
   ✅ No extreme outliers detected - normalization looks good!

🚀 Training 6 models with memory leak prevention...
======================================================================

==================== SVM (1/6) ====================
📊 Memory before svm: 5.26GB

🔧 Training SVM...
📊 Memory before SVM: CPU=5.26GB, GPU=0.09GB
📊 Building SVM model...
🚀 Training SVM...
✅ SVM training completed in 356.4s

Evaluation for SVM
[[10752     0]
 [    0 10752]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00     10752
         EEG       1.00      1.00      1.00     10752

    accuracy                           1.00     21504
   macro avg       1.00      1.00      1.00     21504
weighted avg       1.00      1.00      1.00     21504

💾 SVM model saved
📊 Memory after SVM: CPU=5.29GB, GPU=0.09GB
✅ svm completed in 375.9s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 5.28GB (Δ+0.02GB)

==================== SIMPLE_CNN (2/6) ====================
📊 Memory before simple_cnn: 5.28GB
📊 Dataset size: 86,016 samples
🎯 Using validation strategy: split
🚀 Training simple_cnn with simple split validation...
📊 Memory before simple_cnn: CPU=5.28GB, GPU=0.09GB
🔧 Preparing data for simple_cnn...
   Original data shape: (86016, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (86016, 188, 32)
   Input shape for model: (188, 32)
2025-06-06 01:32:00.517057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:32:00.518187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:32:00.518304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:32:03.809932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:32:03.810559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:32:03.810816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2025-06-06 01:32:03.811000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 01:32:03.811395: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0
2025-06-06 01:32:03.899139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1875 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1
🔧 Creating adam optimizer with lr=0.0001
📊 Model summary for simple_cnn:
   Parameters: 95,409
   Input shape: (188, 32)
2025-06-06 01:32:12.346494: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1862890496 exceeds 10% of free system memory.
2025-06-06 01:32:31.615751: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1862890496 exceeds 10% of free system memory.
                                                                                                                 🧠 Small model (95,409 params) - patience reduced to 8                                 | 0/30 [00:00<?, ?epoch/s]
2025-06-06 01:33:05.201148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907

Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.1.000, Val_Acc=1.000, LR=1.0e-04, GPU=2

Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.1.000, Val_Acc=1.000, LR=5.0e-05, GPU=

Epoch 16: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.1.000, Val_Acc=1.000, LR=2.5e-05, GPU=

Epoch 21: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.=1.000, Val_Acc=1.000, LR=1.2e-05, GPU=
                                                                                                                  🛑 Early stopping: Plateau detected after 8 epochs4/30 [13:17<03:07, 31.32s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GPU=
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ simple_cnn (798.9s):  80%|▊| 24/30 [13:18<03:19, 33.25s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=6.2e
⏱️  Training completed in 834.0s24/30 [13:18<03:07, 31.32s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=6.2e
📈 Training curves saved to: models/simple_cnn_training_20250606_014602.png
🔍 Evaluating on test set...

Evaluation for simple_cnn
[[10752     0]
 [    0 10752]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00     10752
         EEG       1.00      1.00      1.00     10752

    accuracy                           1.00     21504
   macro avg       1.00      1.00      1.00     21504
weighted avg       1.00      1.00      1.00     21504

📊 Memory after simple_cnn: CPU=7.04GB, GPU=2.17GB
✅ simple_cnn model saved
✅ simple_cnn completed in 859.5s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 6.51GB (Δ+1.24GB)

==================== CNN_LSTM (3/6) ====================
📊 Memory before cnn_lstm: 6.51GB
📊 Dataset size: 86,016 samples
🎯 Using validation strategy: split
🚀 Training cnn_lstm with simple split validation...
📊 Memory before cnn_lstm: CPU=6.51GB, GPU=2.17GB
🔧 Preparing data for cnn_lstm...
   Original data shape: (86016, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (86016, 188, 32)
   Input shape for model: (188, 32)
[DEBUG] CNN-LSTM input_shape received: (188, 32)
[INFO] Assuming format: (timesteps=188, features=32)
❌ cnn_lstm failed after 0.1s: list index out of range
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 6.51GB (Δ-0.00GB)

==================== MLP (4/6) ====================
📊 Memory before mlp: 6.51GB
📊 Dataset size: 86,016 samples
🎯 Using validation strategy: split
🚀 Training mlp with simple split validation...
📊 Memory before mlp: CPU=6.51GB, GPU=2.17GB
🔧 Preparing data for mlp...
   Original data shape: (86016, 6016)
   MLP flattened shape: (86016, 6016)
🔧 Creating adam optimizer with lr=0.0001
📊 Model summary for mlp:
   Parameters: 387,201
   Input shape: (6016,)
2025-06-06 01:49:11.900353: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1862890496 exceeds 10% of free system memory.
2025-06-06 01:54:36.273921: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1862890496 exceeds 10% of free system memory.

Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.h] , Loss=0.0003, Acc=1.000, Val_Acc=1.000, LR=1.0e-04, GPU=2.4GB

Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.] , Loss=0.0002, Acc=1.000, Val_Acc=1.000, LR=5.0e-05, GPU=2.4GB

Epoch 16: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.] , Loss=0.0001, Acc=1.000, Val_Acc=1.000, LR=2.5e-05, GPU=2.4GB

Epoch 21: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.h] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e-05, GPU=2.4GB

Epoch 26: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.h] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GPU=2.4GB
                                                                                                                                           🛑 Early stopping: Plateau detected after 12 epochs05:57<00:25, 12.55s/epoch] , Loss=0.0001, Acc=1.000, Val_Acc=1.000, LR=3.1e-06, GPU=2.4GB
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ mlp (358.0s):  93%|██████████████████▋ | 28/30 [05:57<00:25, 12.78s/epoch] , Loss=0.0001, Acc=1.000, Val_Acc=1.000, LR=3.1e-06, GPU=2.4GB
⏱️  Training completed in 870.3s████████▋ | 28/30 [05:57<00:25, 12.55s/epoch] , Loss=0.0001, Acc=1.000, Val_Acc=1.000, LR=3.1e-06, GPU=2.4GB
📈 Training curves saved to: models/mlp_training_20250606_020051.png
🔍 Evaluating on test set...

Evaluation for mlp
[[10751     1]
 [    0 10752]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00     10752
         EEG       1.00      1.00      1.00     10752

    accuracy                           1.00     21504
   macro avg       1.00      1.00      1.00     21504
weighted avg       1.00      1.00      1.00     21504

📊 Memory after mlp: CPU=8.93GB, GPU=2.92GB
✅ mlp model saved
✅ mlp completed in 888.8s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 6.47GB (Δ-0.04GB)

==================== TCN (5/6) ====================
📊 Memory before tcn: 6.47GB
📊 Dataset size: 86,016 samples
🎯 Using validation strategy: split
🚀 Training tcn with simple split validation...
📊 Memory before tcn: CPU=6.47GB, GPU=2.92GB
🔧 Preparing data for tcn...
   Original data shape: (86016, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (86016, 188, 32)
   Input shape for model: (188, 32)
🔧 Creating adam optimizer with lr=0.0001
📊 Model summary for tcn:
   Parameters: 6,497
   Input shape: (188, 32)
2025-06-06 02:02:55.204918: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1862890496 exceeds 10% of free system memory.
                                                                                                                                           🧠 Small model (6,497 params) - patience reduced to 8                                                            | 0/30 [00:00<?, ?epoch/s]
2025-06-06 02:08:58.832116: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 456401920 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)
 Reported by CUDA: Free memory/Total memory: 0/3221094400
2025-06-06 02:08:58.878741: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                      1966971291
InUse:                      2560859728
MaxInUse:                   2660311672
NumAllocs:                    14215183
MaxAllocSize:               1862890496
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-06-06 02:08:58.882099: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;
2025-06-06 02:08:58.882191: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 55
2025-06-06 02:08:58.882202: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 12
2025-06-06 02:08:58.882208: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 1
2025-06-06 02:08:58.882213: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 96, 32
2025-06-06 02:08:58.882218: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 6
2025-06-06 02:08:58.882224: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1
2025-06-06 02:08:58.882251: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2304, 3
2025-06-06 02:08:58.882278: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 3072, 7
2025-06-06 02:08:58.882288: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6912, 3
2025-06-06 02:08:58.882293: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 4
2025-06-06 02:08:58.882298: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36096, 2
2025-06-06 02:08:58.882304: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 48128, 1
2025-06-06 02:08:58.882330: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 48640, 1
2025-06-06 02:08:58.882338: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 68816, 1
2025-06-06 02:08:58.882343: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 619312, 1
2025-06-06 02:08:58.882348: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16813312, 2
2025-06-06 02:08:58.882353: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 206998528, 1
2025-06-06 02:08:58.882359: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 456395776, 1
2025-06-06 02:08:58.882364: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1862890496, 1
2025-06-06 02:08:58.941896: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 2684354560
2025-06-06 02:08:58.941957: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 2560859728
2025-06-06 02:08:58.941967: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 3154116608
2025-06-06 02:08:58.941973: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 2660311672

Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.h] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.0e-04, GPU=2.4GB

Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=5.0e-05, GPU=2.4GB

Epoch 17: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=2.5e-05, GPU=2.4GB

Epoch 22: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.h] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e-05, GPU=2.4GB
                                                                                                                                           🛑 Early stopping: Plateau detected after 8 epochs[30:39<07:11, 71.83s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GPU=2.4GB
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ tcn (1840.4s):  80%|███████████████▏   | 24/30 [30:39<07:39, 76.66s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GPU=2.4GB
⏱️  Training completed in 2107.7s█████▏   | 24/30 [30:39<07:11, 71.83s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GPU=2.4GB
📈 Training curves saved to: models/tcn_training_20250606_023629.png
🔍 Evaluating on test set...
2025-06-06 02:36:52.845605: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 16778368 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)
 Reported by CUDA: Free memory/Total memory: 0/3221094400
2025-06-06 02:36:52.845688: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                      1966971291
InUse:                      2642331084
MaxInUse:                   2660311672
NumAllocs:                    34842687
MaxAllocSize:               1862890496
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-06-06 02:36:52.845711: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;
2025-06-06 02:36:52.845719: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 54
2025-06-06 02:36:52.845725: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 12
2025-06-06 02:36:52.845730: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 1
2025-06-06 02:36:52.845745: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 96, 32
2025-06-06 02:36:52.845758: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 6
2025-06-06 02:36:52.845768: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1
2025-06-06 02:36:52.845776: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2304, 3
2025-06-06 02:36:52.845784: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 3072, 7
2025-06-06 02:36:52.845792: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6912, 3
2025-06-06 02:36:52.845799: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 4
2025-06-06 02:36:52.845807: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 68816, 1
2025-06-06 02:36:52.845814: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 577536, 2
2025-06-06 02:36:52.845822: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 619312, 1
2025-06-06 02:36:52.845829: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 770048, 1
2025-06-06 02:36:52.845836: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 778240, 1
2025-06-06 02:36:52.845842: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777600, 1
2025-06-06 02:36:52.845849: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 17354752, 2
2025-06-06 02:36:52.845856: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 206998528, 1
2025-06-06 02:36:52.845862: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 517472256, 1
2025-06-06 02:36:52.845869: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1862890496, 1
2025-06-06 02:36:52.845878: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 2785017856
2025-06-06 02:36:52.845884: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 2642331084
2025-06-06 02:36:52.845889: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 3154116608
2025-06-06 02:36:52.845895: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 2660311672

Evaluation for tcn
[[10752     0]
 [    0 10752]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00     10752
         EEG       1.00      1.00      1.00     10752

    accuracy                           1.00     21504
   macro avg       1.00      1.00      1.00     21504
weighted avg       1.00      1.00      1.00     21504

📊 Memory after tcn: CPU=6.66GB, GPU=2.17GB
✅ tcn model saved
✅ tcn completed in 2143.4s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 6.13GB (Δ-0.35GB)

==================== DUAL_BRANCH (6/6) ====================
📊 Memory before dual_branch: 6.13GB

🚀 Training Dual-Branch CNN...
📊 Memory before dual_branch: CPU=6.13GB, GPU=2.17GB
🔧 Preparing data for dual_branch...
   Original data shape: (86016, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (86016, 188, 32)
   Input shape for model: (188, 32)
📊 Dataset size: 86,016 samples
🎯 Using validation strategy: split
🔧 Creating adam optimizer with lr=0.0001
📊 Model summary for dual_branch:
   Parameters: 14,721
   Input shape: (188, 32)
📈 dual_branch:   0%|                                                                                            | 0/30 [00:00<?, ?epoch/s] 🧠 Small model (14,721 params) - patience reduced to 8
📈 dual_branch:   3%|▋                  | 1/30 [03:22<1:37:40, 202.10s/epoch] , Loss=0.2114, Acc=0.984, Val_Acc=1.000, LR=1.0e-04, GPU=2.4GB2025-06-06 02:42:15.575566: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at save_restore_v2_ops.cc:160 : PERMISSION_DENIED: models/dual_branch_best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate5266047210793380547; Permission denied
❌ dual_branch failed after 311.4s: {{function_node __wrapped__SaveV2_dtypes_68_device_/job:localhost/replica:0/task:0/device:CPU:0}} models/dual_branch_best/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate5266047210793380547; Permission denied [Op:SaveV2]
📈 dual_branch:   3%|▋                  | 1/30 [03:32<1:42:40, 212.45s/epoch] , Loss=0.2114, Acc=0.984, Val_Acc=1.000, LR=1.0e-04, GPU=2.4GB
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 6.08GB (Δ-0.04GB)

🎉 TRAINING PIPELINE COMPLETE!
======================================================================
⏱️  Total time: 76.6 minutes
📊 Results summary:
   ✅ Successful: 4/6
   ❌ Failed: 2/6
   🚀 Fastest: cnn_lstm (0.1s)
   💥 Failed models: cnn_lstm, dual_branch
📊 Final memory usage: 6.08GB (total change: +5.64GB)

💡 Next steps:
   • Check model performance in the models/ directory
   • Compare training curves to identify best performing models
   • Use the best performing model for inference