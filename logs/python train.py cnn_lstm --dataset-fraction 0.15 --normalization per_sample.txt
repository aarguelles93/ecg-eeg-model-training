(tf-gpu-env) root@DESKTOP-08HJS8G:/mnt/d/Documents/Projects/Thesis/src# python train.py cnn_lstm --dataset-fraction 0.15 --normalization per_sample
🔧 Environment variables set for TensorFlow/CUDA compatibility
✅ Import safety check passed - TensorFlow not yet imported
2025-06-06 08:12:08.368927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-06-06 08:12:16.242324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
🔧 Setting up GPU configuration...
🚀 Setting up GPU-friendly configuration for GTX 1050 (2GB VRAM)...
✅ CUDA libdevice path set to: /usr/lib/cuda
🔧 Configuring GPU memory settings...
2025-06-06 08:12:42.687758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
✅ Found 1 GPU(s): ['/physical_device:GPU:0']
✅ Memory growth enabled for /physical_device:GPU:0
🔧 Configuring TensorFlow memory management...
✅ Memory growth enabled for /physical_device:GPU:0
✅ Using float32 precision (optimized for GTX 1050/Pascal)
   This provides better performance than mixed precision on compute capability 6.1
✅ GPU configuration complete! GTX 1050 optimized with correct CUDA paths.
✅ GPU configuration successful - using optimized settings
🚀 ENHANCED TRAINING PIPELINE
======================================================================
🔧 Normalization: per_sample (strategy: separate)
📊 Dataset fraction: 15.0%
💾 Memory limit: 3.5GB
🎯 Validation strategy: auto
📊 Memory monitoring: Enabled
📈 Progress bars: Enabled
🖥️  GPU optimization: Enabled

📊 Initial system status:
💾 Initial memory usage: 0.44GB

📦 Preparing dataset with smart normalization...
🧠 Memory limit applied: 3.5GB
   📊 Calculated chunk size: 5,000 samples
   📊 Estimated memory per chunk: 0.11GB
🔍 Checking cached dataset: data/preprocessed_dataset.npz
✅ Cache parameters match - loading cached data
📊 Cached data loaded:
   Train: (86016, 6016) | Test: (21504, 6016)
   Range: [-4.826004, 5.000000]
✅ Dataset ready!
   📊 Dataset loaded in 46.1s
   🚀 Train: (86016, 6016), Test: (21504, 6016)
   📉 Using 15.0% of full dataset
   📈 Total features: 6,016
   🧠 EEG structure: 32 channels × 188 timepoints
   💾 Memory usage: 5.26GB (Δ+4.82GB)
   🔢 Data range: [-4.826, 5.000]
   📊 Data stats: mean=-0.002794, std=0.984329
   ✅ No extreme outliers detected - normalization looks good!

🚀 Training 1 models with memory leak prevention...
======================================================================

==================== CNN_LSTM (1/1) ====================
📊 Memory before cnn_lstm: 5.26GB
📊 Dataset size: 86,016 samples
🎯 Using validation strategy: split
🚀 Training cnn_lstm with simple split validation...
📊 Memory before cnn_lstm: CPU=5.26GB, GPU=0.09GB
🔧 Preparing data for cnn_lstm...
   Original data shape: (86016, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (86016, 188, 32)
   Input shape for model: (188, 32)
[DEBUG] CNN-LSTM input_shape received: (188, 32)
[INFO] Assuming format: (timesteps=188, features=32)
2025-06-06 08:14:07.796651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2025-06-06 08:14:07.796755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-06 08:14:07.797340: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0
2025-06-06 08:14:08.087133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1875 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1
🔧 Creating adam optimizer with lr=0.0002
📊 Model summary for cnn_lstm:
   Parameters: 9,649
   Input shape: (188, 32)
2025-06-06 08:14:15.694446: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1862890496 exceeds 10% of free system memory.
2025-06-06 08:16:05.938812: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1862890496 exceeds 10% of free system memory.
                                                                                                                                           🧠 Small model (9,649 params) - patience reduced to 8                                                            | 0/30 [00:00<?, ?epoch/s]
2025-06-06 08:17:27.546877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907
                                                                                                                                           🛑 Early stopping: Plateau detected after 8 epochs[21:57<05:16, 52.74s/epoch] , Loss=0.0042, Acc=0.999, Val_Acc=1.000, LR=2.0e-04, GPU=2.3GB
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ cnn_lstm (1322.0s):  80%|███████████▏  | 24/30 [21:59<05:29, 54.99s/epoch] , Loss=0.0042, Acc=0.999, Val_Acc=1.000, LR=2.0e-04, GPU=2.3GB
⏱️  Training completed in 1453.1s██████▏  | 24/30 [21:59<05:16, 52.74s/epoch] , Loss=0.0042, Acc=0.999, Val_Acc=1.000, LR=2.0e-04, GPU=2.3GB
📈 Training curves saved to: models/cnn_lstm_training_20250606_083829.png
🔍 Evaluating on test set...

Evaluation for cnn_lstm
[[10752     0]
 [    0 10752]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00     10752
         EEG       1.00      1.00      1.00     10752

    accuracy                           1.00     21504
   macro avg       1.00      1.00      1.00     21504
weighted avg       1.00      1.00      1.00     21504

📊 Memory after cnn_lstm: CPU=7.11GB, GPU=2.17GB
✅ cnn_lstm model saved
✅ cnn_lstm completed in 1605.6s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 6.57GB (Δ+1.30GB)

🎉 TRAINING PIPELINE COMPLETE!
======================================================================
⏱️  Total time: 26.8 minutes
📊 Results summary:
   ✅ Successful: 1/1
   ❌ Failed: 0/1
   🚀 Fastest: cnn_lstm (1605.6s)
📊 Final memory usage: 6.57GB (total change: +6.13GB)
