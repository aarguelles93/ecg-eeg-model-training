(venv) root@DESKTOP-08HJS8G:/mnt/d/Documents/Projects/Thesis/src# python train.py all --normalization zscore --dataset-fraction 0.5 --norm-strategy separate
ðŸ”§ Environment variables set for TensorFlow/CUDA compatibility
âœ… Import safety check passed - TensorFlow not yet imported
2025-06-09 02:18:44.585031: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-06-09 02:18:44.585163: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-06-09 02:18:44.608438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-06-09 02:18:44.684545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-06-09 02:18:45.595774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
ðŸ”§ Setting up GPU configuration...
ðŸš€ Setting up GPU-friendly configuration for GTX 1050 (2GB VRAM)...
âœ… CUDA libdevice path set to: /usr/lib/cuda
ðŸ”§ Configuring GPU memory settings...
2025-06-09 02:18:47.750255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:18:47.956914: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:18:47.957019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
âœ… Found 1 GPU(s): ['/physical_device:GPU:0']
âœ… Memory growth enabled for /physical_device:GPU:0
ðŸ”§ Configuring TensorFlow memory management...
âœ… Memory growth enabled for /physical_device:GPU:0
âœ… Using float32 precision (optimized for GTX 1050/Pascal)
   This provides better performance than mixed precision on compute capability 6.1
âœ… GPU configuration complete! GTX 1050 optimized with correct CUDA paths.
âœ… GPU configuration successful - using optimized settings
ðŸš€ ENHANCED TRAINING PIPELINE
======================================================================
ðŸ”§ Normalization: zscore (strategy: separate)
ðŸ“Š Dataset fraction: 50.0%
ðŸ’¾ Memory limit: 3.5GB
ðŸŽ¯ Validation strategy: auto
ðŸ“Š Memory monitoring: Enabled
ðŸ“ˆ Progress bars: Enabled
ðŸ–¥ï¸  GPU optimization: Enabled

ðŸ“Š Initial system status:
ðŸ’¾ Initial memory usage: 0.61GB

ðŸ“¦ Preparing dataset with smart normalization...
ðŸ§  Memory limit applied: 3.5GB
   ðŸ“Š Calculated chunk size: 5,000 samples
   ðŸ“Š Estimated memory per chunk: 0.11GB
ðŸ” Checking cached dataset: data/preprocessed_dataset.npz
âš ï¸ Old cache format - regenerating
ðŸ“ Generating fresh dataset with chunk size: 5,000
ðŸ§  Loading and analyzing EEG data...
ðŸ“Š EEG Dataset Analysis:
   Total samples: 53,760
   Columns: 6017
   Estimated memory: 2467.9 MB
   Feature columns: 6016
   ðŸ“¡ Parsing structured column names...
   ðŸ“¡ Detected from names: 32 channels Ã— 188 timepoints
ðŸ”„ Loading EEG data in chunks...
   Processing EEG chunk 1: samples 0-5,000
   Processing EEG chunk 2: samples 5,000-10,000
   Processing EEG chunk 3: samples 10,000-15,000
   Processing EEG chunk 4: samples 15,000-20,000
   Processing EEG chunk 5: samples 20,000-25,000
   Processing EEG chunk 6: samples 25,000-30,000
   Processing EEG chunk 7: samples 30,000-35,000
   Processing EEG chunk 8: samples 35,000-40,000
   Processing EEG chunk 9: samples 40,000-45,000
   Processing EEG chunk 10: samples 45,000-50,000
   Processing EEG chunk 11: samples 50,000-53,760
   ðŸ”— Combining EEG chunks...
   âœ… EEG data loaded: (53760, 6016)
   ðŸ“Š EEG Statistics:
      Unique labels: [1]
      Data range: [-0.298828, 0.328115]
      Mean: -0.003678, Std: 0.013236
      Memory usage: 2467.5 MB

â¤ï¸  Loading ECG data...
ðŸ“– Loading ECG data from: data/mitbih_from_raw.csv
   ðŸ“Š Raw ECG data shape: (28155, 188)
   ðŸ·ï¸ Original ECG label distribution: [28155]
   âœ‚ï¸ ECG samples after filtering (normal heartbeats only): 28155
   ðŸ“Š ECG feature range: [-3.718426, 3.100260]
   ðŸ“Š ECG statistics: mean=-0.272683, std=0.427785
   âš ï¸ ECG has fewer samples (28,155) than EEG (53,760)
   ðŸŽ¯ Using all available ECG samples
   âœ… Final ECG dataset: (28155, 187)
   ðŸ·ï¸ Binary labels: 28155 samples, all labeled as 0 (ECG)
ECG samples loaded: 28155
   Target size: 28,155 samples each
   ðŸ”„ Downsampling EEG: 53,760 â†’ 28,155
   âœ… Final balanced sizes: ECG=28,155, EEG=28,155
âœ‚ï¸ Applied dataset_fraction before normalization:
   EEG: 14077 samples | ECG: 14077 samples

ðŸ” Advanced feature compatibility check:
   ECG features: 187
   EEG features: 6016
   ðŸ“Š EEG structure: 32 channels Ã— 188 timepoints
   âš ï¸  Feature dimension mismatch!
   ðŸ§  EEG structure: 32 channels Ã— 188 timepoints
   ðŸ”„ Projecting ECG: 187 â†’ 6016 features
   ðŸ“ˆ Expanding ECG dimensions...
   ðŸ”„ Repeated ECG features 32x + 32 extra
   âœ… After projection - ECG: 6016, EEG: 6016

ðŸ”§ APPLYING NORMALIZATION: zscore (strategy: separate)

ðŸ”§ Applying zscore normalization (strategy: separate)

ðŸ” PRE-NORMALIZATION DEBUG (ECG):
   Shape: (14077, 6016)
   Dtype: float64
   Memory: 0.63GB
   Sample size for analysis: 1000
   Overall mean: -0.332668
   Overall std: 0.418852
   Overall range: [-3.718426, 3.100260]
   NaN values: 0
   Infinite values: 0
   Zero values: 0 (0.0%)
   Percentiles:
       0.1%:    -1.916825
       1.0%:    -1.169107
       5.0%:    -0.972650
      25.0%:    -0.486975
      50.0%:    -0.353748
      75.0%:    -0.217157
      95.0%:     0.422692
      99.0%:     1.281444
      99.9%:     1.846579
   IQR outliers (3Ã—IQR): 3,944,397 (4.66%)
   Outlier bounds: [-1.296430, 0.592298]
   Per-feature stats (first 10 features):
     Feature  0: mean= -0.4030, std=  0.2887, range=[ -3.1750,   2.8900]
     Feature  1: mean= -0.4034, std=  0.2889, range=[ -3.1734,   2.9103]
     Feature  2: mean= -0.4032, std=  0.2886, range=[ -3.1705,   2.8984]
     Feature  3: mean= -0.4039, std=  0.2894, range=[ -3.1995,   2.9073]
     Feature  4: mean= -0.4032, std=  0.2892, range=[ -3.1853,   2.8828]
     Feature  5: mean= -0.4037, std=  0.2898, range=[ -3.1951,   2.8878]
     Feature  6: mean= -0.4027, std=  0.2890, range=[ -3.1609,   2.8677]
     Feature  7: mean= -0.4027, std=  0.2897, range=[ -3.1644,   2.8589]
     Feature  8: mean= -0.4013, std=  0.2891, range=[ -3.1700,   2.8093]
     Feature  9: mean= -0.4010, std=  0.2894, range=[ -3.1702,   2.7478]

ðŸ” PRE-NORMALIZATION DEBUG (EEG):
   Shape: (14077, 6016)
   Dtype: float64
   Memory: 0.63GB
   Sample size for analysis: 1000
   Overall mean: -0.003719
   Overall std: 0.013286
   Overall range: [-0.109489, 0.260421]
   NaN values: 0
   Infinite values: 0
   Zero values: 0 (0.0%)
   Percentiles:
       0.1%:    -0.039448
       1.0%:    -0.030656
       5.0%:    -0.023877
      25.0%:    -0.009485
      50.0%:    -0.002925
      75.0%:     0.002760
      95.0%:     0.011322
      99.0%:     0.019521
      99.9%:     0.031385
   IQR outliers (3Ã—IQR): 84,432 (0.10%)
   Outlier bounds: [-0.046220, 0.039495]
   Per-feature stats (first 10 features):
     Feature  0: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0141]
     Feature  1: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0141]
     Feature  2: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0142]
     Feature  3: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0141]
     Feature  4: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0142]
     Feature  5: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0141]
     Feature  6: mean= -0.0102, std=  0.0113, range=[ -0.0377,   0.0141]
     Feature  7: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0141]
     Feature  8: mean= -0.0102, std=  0.0113, range=[ -0.0376,   0.0141]
     Feature  9: mean= -0.0102, std=  0.0113, range=[ -0.0377,   0.0141]

ðŸ“Š Final normalization results:
   ECG: mean=-0.000000, std=1.000000, range=[-14.165, 12.899]
   EEG: mean=-0.000000, std=1.000000, range=[-9.653, 25.076]
   âš ï¸  Warning: Found extreme values (>6 std)
      ECG: 109,502, EEG: 754, Total: 110,256 (0.0651%)
   ðŸš¨ HIGH extreme value percentage detected!
   ðŸ’¡ STRONG recommendation: Use --normalization per_sample
   ðŸ’¡ Or try: python train.py --normalization per_sample --quick-lc

ðŸ” POST-NORMALIZATION DEBUG (ECG):
   Mean: -0.000000
   Std: 1.000000
   Range: [-14.164639, 12.898703]
   âœ… Mean is close to 0
   âœ… Std is close to 1
   âŒ Range is TOO WIDE for z-scores
       Extreme values (|z| > 6): 109,502 (0.129%)
       Most extreme values: [12.89870329 12.89870329 12.89870329 12.89870329 12.89870329 12.89870329
 12.89870329 12.89870329 12.89870329 12.89870329]

ðŸ” POST-NORMALIZATION DEBUG (EEG):
   Mean: -0.000000
   Std: 1.000000
   Range: [-9.652527, 25.075522]
   âœ… Mean is close to 0
   âœ… Std is close to 1
   âŒ Range is TOO WIDE for z-scores
       Extreme values (|z| > 6): 754 (0.001%)
       Most extreme values: [25.03727637 25.04003333 25.04312212 25.04647697 25.0500884  25.05394957
 25.05849486 25.06381952 25.06900097 25.0755223 ]

ðŸ“¦ Combining normalized datasets...
ðŸ” Signal alignment validation:
   ECG samples: 14077
   EEG samples: 14077
   EEG structure: 32ch Ã— 188tp
   âœ… Signal alignment check completed
ðŸ”€ Shuffling data...
Label distribution after shuffle: [14077 14077]

âœ‚ï¸  Splitting into train/test sets...
âœ… Final dataset summary:
   Train set: (22523, 6016) | Labels: [11261 11262]
   Test set:  (5631, 6016) | Labels: [2816 2815]
   Feature range: [-12.536972, 25.075522]
   Final statistics:
      Mean: -0.001578
      Std: 0.999998
   Memory usage: Train=1.01GB, Test=0.25GB

ðŸ“Ž Caching dataset...
   ðŸ”„ Saving compressed arrays...
   âœ… Cached to: data/preprocessed_dataset.npz
âœ… Dataset ready!
   ðŸ“Š Dataset loaded in 583.2s
   ðŸš€ Train: (22523, 6016), Test: (5631, 6016)
   ðŸ“‰ Using 50.0% of full dataset
   ðŸ“ˆ Total features: 6,016
   ðŸ§  EEG structure: 32 channels Ã— 188 timepoints
   ðŸ’¾ Memory usage: 2.18GB (Î”+1.57GB)
   ðŸ”¢ Data range: [-12.537, 25.076]
   ðŸ“Š Data stats: mean=-0.001578, std=0.999998
   âš ï¸  Warning: 87,494 extreme values (>6 std, 0.065%)

ðŸš€ Training 6 models with memory leak prevention...
======================================================================

==================== SVM (1/6) ====================
ðŸ“Š Memory before svm: 2.18GB

ðŸ”§ Training SVM...
ðŸ“Š Memory before SVM: CPU=2.18GB, GPU=0.09GB
ðŸ“Š Building SVM model...
ðŸš€ Training SVM...
âœ… SVM training completed in 300.8s

Evaluation for SVM
[[2816    0]
 [   0 2815]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      2816
         EEG       1.00      1.00      1.00      2815

    accuracy                           1.00      5631
   macro avg       1.00      1.00      1.00      5631
weighted avg       1.00      1.00      1.00      5631

ðŸ’¾ SVM model saved
ðŸ“Š Memory after SVM: CPU=2.22GB, GPU=0.09GB
âœ… svm completed in 317.0s
ðŸ§¹ Cleaning up memory...
ðŸ§¹ Cleaning up TensorFlow memory...
âœ… Memory cleanup completed
ðŸ“Š Memory after cleanup: 1.94GB (Î”-0.24GB)

==================== SIMPLE_CNN (2/6) ====================
ðŸ“Š Memory before simple_cnn: 1.94GB
ðŸ“Š Dataset size: 22,523 samples
ðŸŽ¯ Using validation strategy: split
âš™ï¸  Configuration for SIMPLE_CNN:
   ðŸ“‹ learning_rate: 0.0001
   ðŸ“‹ batch_size: 24
   ðŸ“‹ dropout: 0.5
   ðŸ“‹ filters: [16, 32]
   ðŸ“‹ kernel_sizes: [3, 3]

ðŸš€ Training simple_cnn with simple split validation...
ðŸ“Š Memory before simple_cnn: CPU=1.94GB, GPU=0.09GB
ðŸ”§ Preparing data for simple_cnn...
   Original data shape: (22523, 6016)
   EEG structure: 32 channels Ã— 188 timepoints = 6016 features
   Reshaped to EEG structure: (22523, 188, 32)
   Input shape for model: (188, 32)
2025-06-09 02:33:52.132197: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:33:52.133818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:33:52.133903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:33:54.183243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:33:54.184739: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:33:54.184913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2025-06-09 02:33:54.219235: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-06-09 02:33:54.309419: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-09 02:33:54.318820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1989 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1
ðŸ”§ Creating adam optimizer with lr=0.0001
ðŸ“Š Model summary for simple_cnn:
   Parameters: 95,409
   Input shape: (188, 32)
                                                                                                                 ðŸ§  Small model (95,409 params) - patience reduced to 5                                 | 0/30 [00:00<?, ?epoch/s]
2025-06-09 02:34:29.973803: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907

Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.1.000, Val_Acc=1.000, LR=1.0e-04, GPU=0

Epoch 13: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.1.000, Val_Acc=1.000, LR=5.0e-05, GPU=

Epoch 18: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.1.000, Val_Acc=1.000, LR=2.5e-05, GPU=
                                                                                                                 ðŸ›‘ Early stopping: Plateau detected after 5 epochsepoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e-05, GPU=
   Best val_accuracy: 1.000000 at epoch 15
ðŸ”„ Restoring best weights
âœ… simple_cnn (271.1s):  70%|â–‹| 21/30 [04:30<01:56, 12.90s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e
â±ï¸  Training completed in 276.0s21/30 [04:30<01:30, 10.06s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e
ðŸ“ˆ Training curves saved to: models/simple_cnn_training_20250609_023835.png
ðŸ” Evaluating on test set...

Evaluation for simple_cnn
[[2816    0]
 [   0 2815]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      2816
         EEG       1.00      1.00      1.00      2815

    accuracy                           1.00      5631
   macro avg       1.00      1.00      1.00      5631
weighted avg       1.00      1.00      1.00      5631

ðŸ“Š Memory after simple_cnn: CPU=2.94GB, GPU=0.91GB
âœ… simple_cnn model saved
âœ… simple_cnn completed in 288.4s
ðŸ§¹ Cleaning up memory...
ðŸ§¹ Cleaning up TensorFlow memory...
âœ… Memory cleanup completed
ðŸ“Š Memory after cleanup: 2.80GB (Î”+0.86GB)

==================== CNN_LSTM (3/6) ====================
ðŸ“Š Memory before cnn_lstm: 2.80GB
ðŸ“Š Dataset size: 22,523 samples
ðŸŽ¯ Using validation strategy: split
âš™ï¸  Configuration for CNN_LSTM:
   ðŸ“‹ learning_rate: 0.0002
   ðŸ“‹ batch_size: 32
   ðŸ“‹ dropout: 0.5
   ðŸ“‹ filters: [16, 32]
   ðŸ“‹ kernel_sizes: [3, 3, 3]
   ðŸ“‹ lstm_units: 16
   ðŸ“‹ l2_regularization: 0.0002

ðŸš€ Training cnn_lstm with simple split validation...
ðŸ“Š Memory before cnn_lstm: CPU=2.80GB, GPU=0.91GB
ðŸ”§ Preparing data for cnn_lstm...
   Original data shape: (22523, 6016)
   EEG structure: 32 channels Ã— 188 timepoints = 6016 features
   Reshaped to EEG structure: (22523, 188, 32)
   Input shape for model: (188, 32)
[DEBUG] CNN-LSTM input_shape received: (188, 32)
[INFO] Assuming format: (timesteps=188, features=32)
ðŸ”§ Creating adam optimizer with lr=0.0002
ðŸ“Š Model summary for cnn_lstm:
   Parameters: 9,649
   Input shape: (188, 32)
                                                                                                                 ðŸ§  Small model (9,649 params) - patience reduced to 5                                  | 0/30 [00:00<?, ?epoch/s]
                                                                                                                 ðŸ›‘ Early stopping: Plateau detected after 5 epochsoch] , Loss=0.0107, Acc=0.995, Val_Acc=1.000, LR=2.0e-04, GPU=0.
   Best val_accuracy: 1.000000 at epoch 15
ðŸ”„ Restoring best weights
âœ… cnn_lstm (344.0s):  70%|â–‹| 21/30 [05:43<02:27, 16.38s/epoch] , Loss=0.0107, Acc=0.995, Val_Acc=1.000, LR=2.0e-0
â±ï¸  Training completed in 347.2s/30 [05:43<02:24, 16.10s/epoch] , Loss=0.0107, Acc=0.995, Val_Acc=1.000, LR=2.0e-0
ðŸ“ˆ Training curves saved to: models/cnn_lstm_training_20250609_024428.png
ðŸ” Evaluating on test set...

Evaluation for cnn_lstm
[[2816    0]
 [   0 2815]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      2816
         EEG       1.00      1.00      1.00      2815

    accuracy                           1.00      5631
   macro avg       1.00      1.00      1.00      5631
weighted avg       1.00      1.00      1.00      5631

ðŸ“Š Memory after cnn_lstm: CPU=3.56GB, GPU=1.00GB
âœ… cnn_lstm model saved
âœ… cnn_lstm completed in 352.6s
ðŸ§¹ Cleaning up memory...
ðŸ§¹ Cleaning up TensorFlow memory...
âœ… Memory cleanup completed
ðŸ“Š Memory after cleanup: 2.90GB (Î”+0.10GB)

==================== MLP (4/6) ====================
ðŸ“Š Memory before mlp: 2.90GB
ðŸ“Š Dataset size: 22,523 samples
ðŸŽ¯ Using validation strategy: split
âš™ï¸  Configuration for MLP:
   ðŸ“‹ learning_rate: 0.0001
   ðŸ“‹ batch_size: 48
   ðŸ“‹ dropout1: 0.5
   ðŸ“‹ dropout2: 0.3

ðŸš€ Training mlp with simple split validation...
ðŸ“Š Memory before mlp: CPU=2.90GB, GPU=1.00GB
ðŸ”§ Preparing data for mlp...
   Original data shape: (22523, 6016)
   MLP flattened shape: (22523, 6016)
ðŸ”§ Creating adam optimizer with lr=0.0001
ðŸ“Š Model summary for mlp:
   Parameters: 387,201
   Input shape: (6016,)

Epoch 12: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05., Val_Acc=1.000, LR=1.0e-04, GPU=1.0GB

Epoch 17: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05., Val_Acc=1.000, LR=5.0e-05, GPU=1.0GB

Epoch 22: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05., Val_Acc=1.000, LR=2.5e-05, GPU=1.0GB
                                                                                                                 ðŸ›‘ Early stopping: Plateau detected after 8 epochs] , Loss=0.0011, Acc=1.000, Val_Acc=1.000, LR=1.2e-05, GPU=1.0GB
   Best val_accuracy: 1.000000 at epoch 15
ðŸ”„ Restoring best weights
âœ… mlp (110.6s):  80%|â–Š| 24/30 [01:50<00:27,  4.61s/epoch] , Loss=0.0011, Acc=1.000, Val_Acc=1.000, LR=1.2e-05, GP
â±ï¸  Training completed in 113.8s01:50<00:25,  4.24s/epoch] , Loss=0.0011, Acc=1.000, Val_Acc=1.000, LR=1.2e-05, GP
ðŸ“ˆ Training curves saved to: models/mlp_training_20250609_024628.png
ðŸ” Evaluating on test set...

Evaluation for mlp
[[2816    0]
 [   0 2815]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      2816
         EEG       1.00      1.00      1.00      2815

    accuracy                           1.00      5631
   macro avg       1.00      1.00      1.00      5631
weighted avg       1.00      1.00      1.00      5631

ðŸ“Š Memory after mlp: CPU=3.59GB, GPU=1.00GB
âœ… mlp model saved
âœ… mlp completed in 115.9s
ðŸ§¹ Cleaning up memory...
ðŸ§¹ Cleaning up TensorFlow memory...
âœ… Memory cleanup completed
ðŸ“Š Memory after cleanup: 2.94GB (Î”+0.04GB)

==================== TCN (5/6) ====================
ðŸ“Š Memory before tcn: 2.94GB
ðŸ“Š Dataset size: 22,523 samples
ðŸŽ¯ Using validation strategy: split
âš™ï¸  Configuration for TCN:
   ðŸ“‹ learning_rate: 0.0002
   ðŸ“‹ batch_size: 64
   ðŸ“‹ base_filters: 24
   ðŸ“‹ dropout_rate: 0.1
   ðŸ“‹ dense_units: 32

ðŸš€ Training tcn with simple split validation...
ðŸ“Š Memory before tcn: CPU=2.94GB, GPU=1.00GB
ðŸ”§ Preparing data for tcn...
   Original data shape: (22523, 6016)
   EEG structure: 32 channels Ã— 188 timepoints = 6016 features
   Reshaped to EEG structure: (22523, 188, 32)
   Input shape for model: (188, 32)
ðŸ”§ Creating adam optimizer with lr=0.0002
ðŸ“Š Model summary for tcn:
   Parameters: 8,945
   Input shape: (188, 32)
                                                                                                                 ðŸ§  Small model (8,945 params) - patience reduced to 5                                  | 0/30 [00:00<?, ?epoch/s]
                                                                                                                 ðŸ›‘ Early stopping: Plateau detected after 5 epochs] , Loss=0.0135, Acc=1.000, Val_Acc=1.000, LR=2.0e-04, GPU=2.2GB
   Best val_accuracy: 1.000000 at epoch 15
ðŸ”„ Restoring best weights
âœ… tcn (242.3s):  70%|â–‹| 21/30 [04:02<01:43, 11.54s/epoch] , Loss=0.0135, Acc=1.000, Val_Acc=1.000, LR=2.0e-04, GP
â±ï¸  Training completed in 244.5s04:02<01:39, 11.02s/epoch] , Loss=0.0135, Acc=1.000, Val_Acc=1.000, LR=2.0e-04, GP
ðŸ“ˆ Training curves saved to: models/tcn_training_20250609_025035.png
ðŸ” Evaluating on test set...

Evaluation for tcn
[[2816    0]
 [   0 2815]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      2816
         EEG       1.00      1.00      1.00      2815

    accuracy                           1.00      5631
   macro avg       1.00      1.00      1.00      5631
weighted avg       1.00      1.00      1.00      5631

ðŸ“Š Memory after tcn: CPU=3.69GB, GPU=2.19GB
âœ… tcn model saved
âœ… tcn completed in 249.9s
ðŸ§¹ Cleaning up memory...
ðŸ§¹ Cleaning up TensorFlow memory...
âœ… Memory cleanup completed
ðŸ“Š Memory after cleanup: 3.03GB (Î”+0.09GB)

==================== DUAL_BRANCH (6/6) ====================
ðŸ“Š Memory before dual_branch: 3.03GB

ðŸš€ Training Dual-Branch CNN...
ðŸ“Š Memory before dual_branch: CPU=3.03GB, GPU=2.19GB
ðŸ”§ Preparing data for dual_branch...
   Original data shape: (22523, 6016)
   EEG structure: 32 channels Ã— 188 timepoints = 6016 features
   Reshaped to EEG structure: (22523, 188, 32)
   Input shape for model: (188, 32)
ðŸ“Š Dataset size: 22,523 samples
ðŸŽ¯ Using validation strategy: split
âš™ï¸  Configuration for DUAL_BRANCH:
   ðŸ“‹ learning_rate: 0.0001
   ðŸ“‹ batch_size: 16
   ðŸ“‹ dropout1: 0.3
   ðŸ“‹ dropout2: 0.2
   ðŸ“‹ kernel_sizes:
      ecg: [3, 5]
      eeg: [7, 11]
   ðŸ“‹ base_filters: 12
   ðŸ“‹ l2_regularization: 0.0001

ðŸ”§ Creating adam optimizer with lr=0.0001
ðŸ“Š Model summary for dual_branch:
   Parameters: 8,953
   Input shape: (188, 32)
ðŸ“ˆ dual_branch:   0%|                                                                  | 0/30 [00:00<?, ?epoch/s] ðŸ§  Small model (8,953 params) - patience reduced to 5
ðŸ“ˆ dual_branch:  70%|â–‹| 21/30 [08:12<03:21, 22.41s/epoch] , Loss=0.0744, Acc=0.974, Val_Acc=1.000, LR=1.0e-04, GPUðŸ›‘ Early stopping: Plateau detected after 5 epochs
   Best val_accuracy: 1.000000 at epoch 15
ðŸ”„ Restoring best weights
âœ… dual_branch (492.5s):  70%|â–‹| 21/30 [08:12<03:31, 23.45s/epoch] , Loss=0.0744, Acc=0.974, Val_Acc=1.000, LR=1.0
â±ï¸  Training completed in 495.4s
ðŸ“ˆ Training curves saved to: models/dual_branch_training_20250609_025859.png
ðŸ“Š Classification Report:
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      2816
         EEG       1.00      1.00      1.00      2815

    accuracy                           1.00      5631
   macro avg       1.00      1.00      1.00      5631
weighted avg       1.00      1.00      1.00      5631

ðŸ“‰ Confusion matrix saved to: models/dual_branch_confusion_matrix.png
ðŸ“Š Memory after dual_branch: CPU=3.58GB, GPU=2.19GB
âœ… Dual-Branch CNN training complete.
âœ… dual_branch completed in 503.4s
ðŸ§¹ Cleaning up memory...
ðŸ§¹ Cleaning up TensorFlow memory...
âœ… Memory cleanup completed
ðŸ“Š Memory after cleanup: 3.04GB (Î”+0.02GB)

ðŸŽ‰ TRAINING PIPELINE COMPLETE!
======================================================================
â±ï¸  Total time: 30.5 minutes
ðŸ“Š Results summary:
   âœ… Successful: 6/6
   âŒ Failed: 0/6
   ðŸš€ Fastest: mlp (115.9s)
ðŸ“Š Final memory usage: 3.04GB (total change: +2.43GB)
