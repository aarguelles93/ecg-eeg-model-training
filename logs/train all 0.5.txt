root@DESKTOP-08HJS8G:/mnt/d/Documents/Projects/Thesis/src# python train.py all --reload --dataset-fraction 0.5 --normalization per_sample
🔧 Environment variables set for TensorFlow/CUDA compatibility
✅ Import safety check passed - TensorFlow not yet imported
2025-06-07 00:43:20.132183: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-06-07 00:43:20.132295: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-06-07 00:43:20.441100: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-06-07 00:43:21.363537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-06-07 00:43:26.932259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
🔧 Setting up GPU configuration...
🚀 Setting up GPU-friendly configuration for GTX 1050 (2GB VRAM)...
✅ CUDA libdevice path set to: /usr/lib/cuda
🔧 Configuring GPU memory settings...
2025-06-07 00:43:32.682382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:43:34.922903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:43:34.923085: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
✅ Found 1 GPU(s): ['/physical_device:GPU:0']
✅ Memory growth enabled for /physical_device:GPU:0
🔧 Configuring TensorFlow memory management...
✅ Memory growth enabled for /physical_device:GPU:0
✅ Using float32 precision (optimized for GTX 1050/Pascal)
   This provides better performance than mixed precision on compute capability 6.1
✅ GPU configuration complete! GTX 1050 optimized with correct CUDA paths.
✅ GPU configuration successful - using optimized settings
🚀 ENHANCED TRAINING PIPELINE
======================================================================
🔧 Normalization: per_sample (strategy: separate)
📊 Dataset fraction: 50.0%
💾 Memory limit: 3.5GB
🎯 Validation strategy: auto
📊 Memory monitoring: Enabled
📈 Progress bars: Enabled
🖥️  GPU optimization: Enabled

📊 Initial system status:
💾 Initial memory usage: 0.61GB

📦 Preparing dataset with smart normalization...
🧠 Memory limit applied: 3.5GB
   📊 Calculated chunk size: 5,000 samples
   📊 Estimated memory per chunk: 0.11GB
📝 Generating fresh dataset with chunk size: 5,000
🧠 Loading and analyzing EEG data...
📊 EEG Dataset Analysis:
   Total samples: 53,760
   Columns: 6017
   Estimated memory: 2467.9 MB
   Feature columns: 6016
   📡 Parsing structured column names...
   📡 Detected from names: 32 channels × 188 timepoints
🔄 Loading EEG data in chunks...
   Processing EEG chunk 1: samples 0-5,000
   Processing EEG chunk 2: samples 5,000-10,000
   Processing EEG chunk 3: samples 10,000-15,000
   Processing EEG chunk 4: samples 15,000-20,000
   Processing EEG chunk 5: samples 20,000-25,000
   Processing EEG chunk 6: samples 25,000-30,000
   Processing EEG chunk 7: samples 30,000-35,000
   Processing EEG chunk 8: samples 35,000-40,000
   Processing EEG chunk 9: samples 40,000-45,000
   Processing EEG chunk 10: samples 45,000-50,000
   Processing EEG chunk 11: samples 50,000-53,760
   🔗 Combining EEG chunks...
   ✅ EEG data loaded: (53760, 6016)
   📊 EEG Statistics:
      Unique labels: [1]
      Data range: [-0.298828, 0.328115]
      Mean: -0.003678, Std: 0.013236
      Memory usage: 2467.5 MB

❤️  Loading ECG data...
📖 Loading ECG data from: data/mitbih_train.csv
   📊 Raw ECG data shape: (87553, 188)
   🏷️ Original ECG label distribution: [72470  2223  5788   641  6431]
   ✂️ ECG samples after filtering (normal heartbeats only): 72470
   📊 ECG feature range: [0.000000, 1.000000]
   📊 ECG statistics: mean=0.161897, std=0.217563
   ⚖️ Balancing ECG to match EEG size: 53,760 samples
   ✅ ECG balanced to: 53,760 samples
   ✅ Final ECG dataset: (53760, 187)
   🏷️ Binary labels: 53760 samples, all labeled as 0 (ECG)
ECG samples loaded: 53760
✂️ Applied dataset_fraction before normalization:
   EEG: 26880 samples | ECG: 26880 samples

🔍 Advanced feature compatibility check:
   ECG features: 187
   EEG features: 6016
   📊 EEG structure: 32 channels × 188 timepoints
   ⚠️  Feature dimension mismatch!
   🧠 EEG structure: 32 channels × 188 timepoints
   🔄 Projecting ECG: 187 → 6016 features
   📈 Expanding ECG dimensions...
   🔄 Repeated ECG features 32x + 32 extra
   ✅ After projection - ECG: 6016, EEG: 6016

🔧 APPLYING NORMALIZATION: per_sample (strategy: separate)

🔧 Applying per_sample normalization (strategy: separate)

🔍 PRE-NORMALIZATION DEBUG (ECG):
   Shape: (26880, 6016)
   Dtype: float64
   Memory: 1.20GB
   Sample size for analysis: 1000
   Overall mean: 0.163178
   Overall std: 0.218215
   Overall range: [0.000000, 1.000000]
   NaN values: 0
   Infinite values: 0
   Zero values: 66,235,318 (41.0%)
   Percentiles:
       0.1%:     0.000000
       1.0%:     0.000000
       5.0%:     0.000000
      25.0%:     0.000000
      50.0%:     0.076253
      75.0%:     0.268443
      95.0%:     0.630390
      99.0%:     0.959128
      99.9%:     1.000000
   IQR outliers (3×IQR): 0 (0.00%)
   Outlier bounds: [-0.805328, 1.073771]
   Per-feature stats (first 10 features):
     Feature  0: mean=  0.9148, std=  0.2134, range=[  0.0000,   1.0000]
     Feature  1: mean=  0.7783, std=  0.1975, range=[  0.0000,   1.0000]
     Feature  2: mean=  0.4039, std=  0.2140, range=[  0.0000,   1.0000]
     Feature  3: mean=  0.1786, std=  0.1665, range=[  0.0000,   1.0000]
     Feature  4: mean=  0.1652, std=  0.1331, range=[  0.0000,   1.0000]
     Feature  5: mean=  0.1812, std=  0.1406, range=[  0.0000,   0.9915]
     Feature  6: mean=  0.1808, std=  0.1567, range=[  0.0000,   1.0000]
     Feature  7: mean=  0.1815, std=  0.1636, range=[  0.0000,   1.0000]
     Feature  8: mean=  0.1842, std=  0.1662, range=[  0.0000,   1.0000]
     Feature  9: mean=  0.1894, std=  0.1671, range=[  0.0000,   1.0000]
   ⚠️  Data appears to already be min-max normalized!

🔍 PRE-NORMALIZATION DEBUG (EEG):
   Shape: (26880, 6016)
   Dtype: float64
   Memory: 1.20GB
   Sample size for analysis: 1000
   Overall mean: -0.001871
   Overall std: 0.010795
   Overall range: [-0.298828, 0.328115]
   NaN values: 0
   Infinite values: 0
   Zero values: 0 (0.0%)
   Percentiles:
       0.1%:    -0.037280
       1.0%:    -0.030401
       5.0%:    -0.023047
      25.0%:    -0.007401
      50.0%:    -0.000371
      75.0%:     0.004799
      95.0%:     0.014059
      99.0%:     0.021468
      99.9%:     0.028777
   IQR outliers (3×IQR): 5,636 (0.00%)
   Outlier bounds: [-0.044004, 0.041401]
   Per-feature stats (first 10 features):
     Feature  0: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
     Feature  1: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
     Feature  2: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
     Feature  3: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
     Feature  4: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0080]
     Feature  5: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
     Feature  6: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0080]
     Feature  7: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
     Feature  8: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
     Feature  9: mean= -0.0078, std=  0.0101, range=[ -0.0320,   0.0079]
🔧 Using per-sample normalization for both datasets...
🔧 Applying OPTIMAL per-sample normalization (clip at ±5.0σ)...
   📊 Based on empirical analysis: eliminates >6σ values, minimal data loss
   Input shape: (26880, 6016)
   Input range: [0.000000, 1.000000]
   Input stats: mean=0.163178, std=0.218215
   📊 Before clipping analysis:
      >6σ values: 298,540 (0.1846%)
      >5σ values: 962,445 (0.5952%)
      >5.0σ values: 962,445 (0.5952%)
   ✂️  Applied 5.0σ clipping:
      Values clipped: 962,445
      Std reduction: 2.6% (from 1.000 to 0.974)
   📊 Post-clipping validation:
      >6σ values: 0 (target: 0)
      >5σ values: 0 (expected: 0 for 5.0σ clipping)
      Final range: [-4.826, 5.000]
      Final stats: mean=-0.004565, std=0.973734
   ✅ PERFECT: All extreme values eliminated!
   🎯 Training stability prediction: EXCELLENT
🔧 Applying OPTIMAL per-sample normalization (clip at ±4.5σ)...
   📊 Based on empirical analysis: eliminates >6σ values, minimal data loss
   Input shape: (26880, 6016)
   Input range: [-0.298828, 0.328115]
   Input stats: mean=-0.001871, std=0.010795
   📊 Before clipping analysis:
      >6σ values: 312 (0.0002%)
      >5σ values: 3,600 (0.0022%)
      >4.5σ values: 3,619 (0.0022%)
   ✂️  Applied 4.5σ clipping:
      Values clipped: 3,619
      Std reduction: 0.0% (from 1.000 to 1.000)
   📊 Post-clipping validation:
      >6σ values: 0 (target: 0)
      >5σ values: 0 (expected: 0 for 5.0σ clipping)
      Final range: [-4.500, 4.500]
      Final stats: mean=-0.000023, std=0.999872
   ✅ PERFECT: All extreme values eliminated!
   🎯 Training stability prediction: EXCELLENT

📊 Final normalization results:
   ECG: mean=-0.004565, std=0.973734, range=[-4.826, 5.000]
   EEG: mean=-0.000023, std=0.999872, range=[-4.500, 4.500]
   ✅ No extreme outliers detected - normalization is optimal!

🔍 POST-NORMALIZATION DEBUG (ECG):
   Mean: -0.004565
   Std: 0.973734
   Range: [-4.826004, 5.000000]
   ❌ Mean is NOT close to 0 (z-score)
   ❌ Std is NOT close to 1 (z-score)
   ✅ Range is reasonable for z-scores

🔍 POST-NORMALIZATION DEBUG (EEG):
   Mean: -0.000023
   Std: 0.999872
   Range: [-4.500000, 4.500000]
   ✅ Mean is close to 0
   ✅ Std is close to 1
   ✅ Range is reasonable for z-scores

📦 Combining normalized datasets...
🔍 Signal alignment validation:
   ECG samples: 26880
   EEG samples: 26880
   EEG structure: 32ch × 188tp
   ✅ Signal alignment check completed
🔀 Shuffling data...
Label distribution after shuffle: [26880 26880]

✂️  Splitting into train/test sets...
✅ Final dataset summary:
   Train set: (43008, 6016) | Labels: [21504 21504]
   Test set:  (10752, 6016) | Labels: [5376 5376]
   Feature range: [-4.826004, 5.000000]
   Final statistics:
      Mean: -0.002311
      Std: 0.986788
   Memory usage: Train=1.93GB, Test=0.48GB

📎 Caching dataset...
   🔄 Saving compressed arrays...
   ✅ Cached to: data/preprocessed_dataset.npz
✅ Dataset ready!
   📊 Dataset loaded in 608.5s
   🚀 Train: (43008, 6016), Test: (10752, 6016)
   📉 Using 50.0% of full dataset
   📈 Total features: 6,016
   🧠 EEG structure: 32 channels × 188 timepoints
   💾 Memory usage: 3.32GB (Δ+2.71GB)
   🔢 Data range: [-4.826, 5.000]
   📊 Data stats: mean=-0.002311, std=0.986788
   ✅ No extreme outliers detected - normalization looks good!

🚀 Training 6 models with memory leak prevention...
======================================================================

==================== SVM (1/6) ====================
📊 Memory before svm: 3.32GB

🔧 Training SVM...
📊 Memory before SVM: CPU=3.32GB, GPU=0.09GB
📊 Building SVM model...
🚀 Training SVM...
✅ SVM training completed in 163.7s

Evaluation for SVM
[[5376    0]
 [   0 5376]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      5376
         EEG       1.00      1.00      1.00      5376

    accuracy                           1.00     10752
   macro avg       1.00      1.00      1.00     10752
weighted avg       1.00      1.00      1.00     10752

💾 SVM model saved
📊 Memory after SVM: CPU=3.34GB, GPU=0.09GB
✅ svm completed in 173.1s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 3.08GB (Δ-0.24GB)

==================== SIMPLE_CNN (2/6) ====================
📊 Memory before simple_cnn: 3.08GB
📊 Dataset size: 43,008 samples
🎯 Using validation strategy: split
⚙️  Configuration for SIMPLE_CNN:
   📋 learning_rate: 0.0001
   📋 batch_size: 24
   📋 dropout: 0.5
   📋 filters: [16, 32]
   📋 kernel_sizes: [3, 3]

🚀 Training simple_cnn with simple split validation...
📊 Memory before simple_cnn: CPU=3.08GB, GPU=0.09GB
🔧 Preparing data for simple_cnn...
   Original data shape: (43008, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (43008, 188, 32)
   Input shape for model: (188, 32)
2025-06-07 00:56:47.712081: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:56:47.712892: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:56:47.712975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:56:48.833624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:56:48.833893: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:56:48.834088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2025-06-07 00:56:48.834387: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-06-07 00:56:48.920942: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2025-06-07 00:56:48.921160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1989 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1
🔧 Creating adam optimizer with lr=0.0001
📊 Model summary for simple_cnn:
   Parameters: 95,409
   Input shape: (188, 32)
                                                                                                                 🧠 Small model (95,409 params) - patience reduced to 5                                 | 0/30 [00:00<?, ?epoch/s]
2025-06-07 00:57:10.573255: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907

Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.1.000, Val_Acc=1.000, LR=1.0e-04, GPU=1

Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.1.000, Val_Acc=1.000, LR=5.0e-05, GPU=

Epoch 16: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.1.000, Val_Acc=1.000, LR=2.5e-05, GPU=
                                                                                                                 🛑 Early stopping: Plateau detected after 5 epochsepoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e-05, GPU=
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights

Epoch 21: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.
✅ simple_cnn (458.2s):  70%|▋| 21/30 [07:38<03:16, 21.82s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e
⏱️  Training completed in 462.9s21/30 [07:38<03:00, 20.01s/epoch] , Loss=0.0000, Acc=1.000, Val_Acc=1.000, LR=1.2e
📈 Training curves saved to: models/simple_cnn_training_20250607_010434.png
🔍 Evaluating on test set...

Evaluation for simple_cnn
[[5376    0]
 [   0 5376]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      5376
         EEG       1.00      1.00      1.00      5376

    accuracy                           1.00     10752
   macro avg       1.00      1.00      1.00     10752
weighted avg       1.00      1.00      1.00     10752

📊 Memory after simple_cnn: CPU=4.18GB, GPU=1.50GB
✅ simple_cnn model saved
✅ simple_cnn completed in 473.8s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 3.92GB (Δ+0.84GB)

==================== CNN_LSTM (3/6) ====================
📊 Memory before cnn_lstm: 3.92GB
📊 Dataset size: 43,008 samples
🎯 Using validation strategy: split
⚙️  Configuration for CNN_LSTM:
   📋 learning_rate: 0.0002
   📋 batch_size: 32
   📋 dropout: 0.5
   📋 filters: [16, 32]
   📋 kernel_sizes: [3, 3, 3]
   📋 lstm_units: 16
   📋 l2_regularization: 0.0002

🚀 Training cnn_lstm with simple split validation...
📊 Memory before cnn_lstm: CPU=3.92GB, GPU=1.50GB
🔧 Preparing data for cnn_lstm...
   Original data shape: (43008, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (43008, 188, 32)
   Input shape for model: (188, 32)
[DEBUG] CNN-LSTM input_shape received: (188, 32)
[INFO] Assuming format: (timesteps=188, features=32)
🔧 Creating adam optimizer with lr=0.0002
📊 Model summary for cnn_lstm:
   Parameters: 9,649
   Input shape: (188, 32)
                                                                                                                 🧠 Small model (9,649 params) - patience reduced to 5                                  | 0/30 [00:00<?, ?epoch/s]
                                                                                                                 🛑 Early stopping: Plateau detected after 5 epochsoch] , Loss=0.0050, Acc=0.999, Val_Acc=1.000, LR=2.0e-04, GPU=1.
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ cnn_lstm (609.4s):  70%|▋| 21/30 [10:09<04:21, 29.02s/epoch] , Loss=0.0050, Acc=0.999, Val_Acc=1.000, LR=2.0e-0
⏱️  Training completed in 615.3s/30 [10:09<04:13, 28.15s/epoch] , Loss=0.0050, Acc=0.999, Val_Acc=1.000, LR=2.0e-0
📈 Training curves saved to: models/cnn_lstm_training_20250607_011456.png
🔍 Evaluating on test set...

Evaluation for cnn_lstm
[[5376    0]
 [   0 5376]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      5376
         EEG       1.00      1.00      1.00      5376

    accuracy                           1.00     10752
   macro avg       1.00      1.00      1.00     10752
weighted avg       1.00      1.00      1.00     10752

📊 Memory after cnn_lstm: CPU=5.29GB, GPU=1.56GB
✅ cnn_lstm model saved
✅ cnn_lstm completed in 622.2s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 4.05GB (Δ+0.12GB)

==================== MLP (4/6) ====================
📊 Memory before mlp: 4.05GB
📊 Dataset size: 43,008 samples
🎯 Using validation strategy: split
⚙️  Configuration for MLP:
   📋 learning_rate: 0.0001
   📋 batch_size: 48
   📋 dropout1: 0.5
   📋 dropout2: 0.3

🚀 Training mlp with simple split validation...
📊 Memory before mlp: CPU=4.05GB, GPU=1.56GB
🔧 Preparing data for mlp...
   Original data shape: (43008, 6016)
   MLP flattened shape: (43008, 6016)
🔧 Creating adam optimizer with lr=0.0001
📊 Model summary for mlp:
   Parameters: 387,201
   Input shape: (6016,)

Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.0, Val_Acc=1.000, LR=1.0e-04, GPU=1.6GB

Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05., Val_Acc=1.000, LR=5.0e-05, GPU=1.6GB

Epoch 16: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05., Val_Acc=1.000, LR=2.5e-05, GPU=1.6GB

Epoch 21: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.0, Val_Acc=1.000, LR=1.2e-05, GPU=1.6GB
                                                                                                                 🛑 Early stopping: Plateau detected after 8 epochs] , Loss=0.0001, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GPU=1.6GB
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ mlp (209.4s):  80%|▊| 24/30 [03:29<00:52,  8.72s/epoch] , Loss=0.0001, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GP
⏱️  Training completed in 215.1s03:29<00:53,  8.99s/epoch] , Loss=0.0001, Acc=1.000, Val_Acc=1.000, LR=6.2e-06, GP
📈 Training curves saved to: models/mlp_training_20250607_011838.png
🔍 Evaluating on test set...

Evaluation for mlp
[[5376    0]
 [   0 5376]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      5376
         EEG       1.00      1.00      1.00      5376

    accuracy                           1.00     10752
   macro avg       1.00      1.00      1.00     10752
weighted avg       1.00      1.00      1.00     10752

📊 Memory after mlp: CPU=5.33GB, GPU=1.56GB
✅ mlp model saved
✅ mlp completed in 217.9s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 4.10GB (Δ+0.05GB)

==================== TCN (5/6) ====================
📊 Memory before tcn: 4.10GB
📊 Dataset size: 43,008 samples
🎯 Using validation strategy: split
⚙️  Configuration for TCN:
   📋 learning_rate: 0.0002
   📋 batch_size: 64
   📋 base_filters: 24
   📋 dropout_rate: 0.1
   📋 dense_units: 32

🚀 Training tcn with simple split validation...
📊 Memory before tcn: CPU=4.10GB, GPU=1.56GB
🔧 Preparing data for tcn...
   Original data shape: (43008, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (43008, 188, 32)
   Input shape for model: (188, 32)
🔧 Creating adam optimizer with lr=0.0002
📊 Model summary for tcn:
   Parameters: 8,945
   Input shape: (188, 32)
                                                                                                                 🧠 Small model (8,945 params) - patience reduced to 5                                  | 0/30 [00:00<?, ?epoch/s]
2025-06-07 01:18:51.316940: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 1911660544 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)
 Reported by CUDA: Free memory/Total memory: 402495899/3221094400
2025-06-07 01:18:51.317028: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                      2086508955
InUse:                       961137580
MaxInUse:                   2614480284
NumAllocs:                    11390532
MaxAllocSize:               1641127936
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2025-06-07 01:18:51.317112: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;
2025-06-07 01:18:51.317184: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 90
2025-06-07 01:18:51.317200: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 15
2025-06-07 01:18:51.317241: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 1
2025-06-07 01:18:51.317313: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 12
2025-06-07 01:18:51.317370: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 96, 47
2025-06-07 01:18:51.317450: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 21
2025-06-07 01:18:51.317515: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 12
2025-06-07 01:18:51.317584: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 3
2025-06-07 01:18:51.317630: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1
2025-06-07 01:18:51.317688: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2304, 6
2025-06-07 01:18:51.317742: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 3072, 9
2025-06-07 01:18:51.317757: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4096, 3
2025-06-07 01:18:51.317797: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6144, 12
2025-06-07 01:18:51.317851: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6912, 7
2025-06-07 01:18:51.317904: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8192, 6
2025-06-07 01:18:51.317919: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 4
2025-06-07 01:18:51.317959: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 12288, 3
2025-06-07 01:18:51.318004: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 309656, 1
2025-06-07 01:18:51.318020: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 368640, 3
2025-06-07 01:18:51.318031: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1155072, 3
2025-06-07 01:18:51.318089: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1540096, 4
2025-06-07 01:18:51.318105: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1556480, 1
2025-06-07 01:18:51.318144: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16780288, 1
2025-06-07 01:18:51.318204: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 931445248, 1
2025-06-07 01:18:51.318465: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 2080374784
2025-06-07 01:18:51.318541: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 961137580
2025-06-07 01:18:51.318609: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 2986344448
2025-06-07 01:18:51.318656: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 2614480284
                                                                                                                  🛑 Early stopping: Plateau detected after 5 epochsn:  70%|██ | 21/30 [07:16<03:01, 20.21s/epoch] , Loss=0.0005, Acc=1.000, Val_Acc=1.000, LR=2.0e-04, GPU=2.2GB
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ tcn (436.9s):  70%|▋| 21/30 [07:16<03:07, 20.80s/epoch] , Loss=0.0005, Acc=1.000, Val_Acc=1.000, LR=2.0e-04, GP
⏱️  Training completed in 440.9s07:16<03:01, 20.21s/epoch] , Loss=0.0005, Acc=1.000, Val_Acc=1.000, LR=2.0e-04, GP
📈 Training curves saved to: models/tcn_training_20250607_012602.png
🔍 Evaluating on test set...

Evaluation for tcn
[[5376    0]
 [   0 5376]]
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      5376
         EEG       1.00      1.00      1.00      5376

    accuracy                           1.00     10752
   macro avg       1.00      1.00      1.00     10752
weighted avg       1.00      1.00      1.00     10752

📊 Memory after tcn: CPU=5.44GB, GPU=2.19GB
✅ tcn model saved
✅ tcn completed in 455.1s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 4.20GB (Δ+0.10GB)

==================== DUAL_BRANCH (6/6) ====================
📊 Memory before dual_branch: 4.20GB

🚀 Training Dual-Branch CNN...
📊 Memory before dual_branch: CPU=4.20GB, GPU=2.19GB
🔧 Preparing data for dual_branch...
   Original data shape: (43008, 6016)
   EEG structure: 32 channels × 188 timepoints = 6016 features
   Reshaped to EEG structure: (43008, 188, 32)
   Input shape for model: (188, 32)
📊 Dataset size: 43,008 samples
🎯 Using validation strategy: split
⚙️  Configuration for DUAL_BRANCH:
   📋 learning_rate: 0.0001
   📋 batch_size: 16
   📋 dropout1: 0.3
   📋 dropout2: 0.2
   📋 kernel_sizes:
      ecg: [3, 5]
      eeg: [7, 11]
   📋 base_filters: 12
   📋 l2_regularization: 0.0001

🔧 Creating adam optimizer with lr=0.0001
📊 Model summary for dual_branch:
   Parameters: 8,953
   Input shape: (188, 32)
📈 dual_branch:   0%|                                                                                                               | 0/30 [00:00<?, ?epoch/s] 🧠 Small model (8,953 params) - patience reduced to 5
📈 dual_branch:  70%|████████████████████████████            | 21/30 [15:52<06:40, 44.54s/epoch] , Loss=0.0251, Acc=0.995, Val_Acc=1.000, LR=1.0e-04, GPU=2.2GB🛑 Early stopping: Plateau detected after 5 epochs
   Best val_accuracy: 1.000000 at epoch 15
🔄 Restoring best weights
✅ dual_branch (952.1s):  70%|█████████████████████▋         | 21/30 [15:52<06:48, 45.34s/epoch] , Loss=0.0251, Acc=0.995, Val_Acc=1.000, LR=1.0e-04, GPU=2.2GB
⏱️  Training completed in 958.1s
📈 Training curves saved to: models/dual_branch_training_20250607_014216.png
📊 Classification Report:
              precision    recall  f1-score   support

         ECG       1.00      1.00      1.00      5376
         EEG       1.00      1.00      1.00      5376

    accuracy                           1.00     10752
   macro avg       1.00      1.00      1.00     10752
weighted avg       1.00      1.00      1.00     10752

📉 Confusion matrix saved to: models/dual_branch_confusion_matrix.png
📊 Memory after dual_branch: CPU=5.21GB, GPU=2.19GB
✅ Dual-Branch CNN training complete.
✅ dual_branch completed in 965.2s
🧹 Cleaning up memory...
🧹 Cleaning up TensorFlow memory...
✅ Memory cleanup completed
📊 Memory after cleanup: 4.22GB (Δ+0.02GB)

🎉 TRAINING PIPELINE COMPLETE!
======================================================================
⏱️  Total time: 48.6 minutes
📊 Results summary:
   ✅ Successful: 6/6
   ❌ Failed: 0/6
   🚀 Fastest: svm (173.1s)
📊 Final memory usage: 4.22GB (total change: +3.61GB)